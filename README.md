
 ## Task 5 â€“ Decision Tree & Random Forest Classifier (Heart Disease Prediction)
# ðŸ“Œ Objective
The goal of this task is to:

Train a Decision Tree Classifier and visualize it.
Analyze overfitting and control the tree depth.
Train a Random Forest Classifier and compare it with Decision Tree.
Interpret feature importances.
Evaluate models using Cross-Validation.

 # ðŸ“‚ Dataset
Name: heart.csv
Description: Contains patient medical details (age, cholesterol, etc.) and whether they have heart disease (target column: 1 = yes, 0 = no).

 # ðŸ›  Libraries Used
pandas â†’ data handling
numpy â†’ numerical operations
matplotlib â†’ plotting graphs
scikit-learn â†’ machine learning models & evaluation

# ðŸš€ Steps Performed
Step 0 â€“ Load & Prepare Data
Loaded the CSV using pandas.
Split the data into:
X = features (all columns except target)
y = target (target column)
Train-test split (80% train, 20% test) using train_test_split.
Step 1 â€“ Train & Visualize Decision Tree
Created a DecisionTreeClassifier.
Trained the model on X_train, y_train.
Printed Accuracy, Classification Report, and Confusion Matrix.
Used plot_tree() to visualize the trained tree.
Step 2 â€“ Overfitting Analysis
Trained multiple Decision Trees with different max_depth values (1â€“20).
Plotted Train Accuracy vs Test Accuracy to detect overfitting.
Selected the max_depth with the highest test accuracy.
Step 3 â€“ Random Forest
Created a RandomForestClassifier with 100 trees.
Trained it and compared accuracy with Decision Tree.
Calculated ROC-AUC to measure classification quality.
Step 4 â€“ Feature Importances
Extracted and sorted feature_importances_ from Random Forest.
Displayed top 10 features and plotted them as a bar chart.
Step 5 â€“ Cross-Validation
Used Stratified 5-Fold Cross-Validation to evaluate both models.
Printed mean accuracy and standard deviation for:
Random Forest
Pruned Decision Tree (best max_depth from Step 2)

# ðŸ“Œ Key Insights
Decision Tree can overfit if max_depth is too high.
Random Forest usually performs better due to averaging multiple trees.
Feature importance shows which health metrics are most useful for prediction.

# ðŸ“· Outputs
Include screenshots of:
Decision Tree visualization
Overfitting plot
Feature importanceÂ barÂ chart
